{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.3: Min-max agent\n",
    "Player 0 = maximizing <br/>\n",
    "Player 1 = minimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\") # move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_new_states(init_state: list) -> list:\n",
    "    \"\"\"Define all possible new states and return them as a list\"\"\"\n",
    "    possible_new_states = []\n",
    "\n",
    "    for row in range(len(init_state)): # for every row\n",
    "        for i in range(init_state[row]): # for the number of elem in row\n",
    "            new_state = deepcopy(init_state)\n",
    "\n",
    "            new_state[row] = new_state[row] - i - 1 #take away i+1 number of elem\n",
    "            #print(\"new state: \", new_state)\n",
    "            possible_new_states.append(new_state)\n",
    "            #print(possible_new_states)\n",
    "    #logging.debug(f\"All possible new states: {possible_new_states}\")\n",
    "    return possible_new_states\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poss state:  [[0, 3, 5], [1, 2, 5], [1, 1, 5], [1, 0, 5], [1, 3, 4], [1, 3, 3], [1, 3, 2], [1, 3, 1], [1, 3, 0]]\n"
     ]
    }
   ],
   "source": [
    "state = [1,3,5]\n",
    "print(\"poss state: \", all_possible_new_states(state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(state_as_list: list, player: int) -> int:\n",
    "    \"\"\"Evaluate if the game is over. Returns: \n",
    "    -1 if player 0 (maximizing) won\n",
    "    1 if player 1 (minimizing) won\n",
    "    None if the game is not over yet\"\"\"\n",
    "    \n",
    "    if sum(state_as_list) == 0: # if game is over\n",
    "        return -1 if player == 0 else 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(state_as_list: list, player: int) -> int:\n",
    "    \"\"\"Calculates all possible moves using the minmax method from a given state and then returns the score. It returns the best score considering the player.\n",
    "    for player 0, best score is 1\n",
    "    for player 1, best score is -1\"\"\"\n",
    "    score = evaluate(state_as_list, player)\n",
    "\n",
    "    if score != None:\n",
    "        # if game is over\n",
    "        return score\n",
    "\n",
    "    if (player == 0): # if it is the maximizings turn\n",
    "        scores = [minimax(new_state, player=1) for new_state in all_possible_new_states(state_as_list)]\n",
    "        return max(scores)\n",
    "    \n",
    "    else: # if it is the minimizings turn\n",
    "        scores = [minimax(new_state, player=0) for new_state in all_possible_new_states(state_as_list)]\n",
    "        return min(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move(state_as_list: list, player: int) -> tuple:\n",
    "    \"\"\"Returns a tuple (winner, new_state)\"\"\"\n",
    "    if player == 0: # if it is the maximizings turn\n",
    "        new_player = 1 \n",
    "        \n",
    "        # calculate the moves for the minimizer and then pic the best one\n",
    "        return max(\n",
    "            (minimax(new_state, new_player), new_state) \n",
    "            for new_state in all_possible_new_states(state_as_list)\n",
    "        )\n",
    "    else: # it is the minimizings turn\n",
    "        new_player = 0\n",
    "\n",
    "        #calculate the moves for the maximizer and then try to minimize them\n",
    "        return min( \n",
    "            (minimax(new_state, new_player), new_state)\n",
    "        for new_state in all_possible_new_states(state_as_list))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, [1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "test = [1,1,5]\n",
    "t = best_move(test, 1)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_pruning(state_as_list: list, is_maximizing: bool, alpha=-1, beta=1) -> int:\n",
    "    if (score := evaluate(state_as_list, is_maximizing)) is not None: \n",
    "        # if the game is over\n",
    "        return score\n",
    "\n",
    "    scores = []\n",
    "    for new_state in all_possible_new_states(state_as_list):\n",
    "        scores.append(\n",
    "            score := minimax_pruning(new_state, not is_maximizing, alpha, beta)\n",
    "        )\n",
    "        \n",
    "        if is_maximizing:\n",
    "            alpha = max(alpha, score)\n",
    "        else:\n",
    "            beta = min(beta, score)\n",
    "\n",
    "        if beta <= alpha:\n",
    "            break\n",
    "        \n",
    "    return (max if is_maximizing else min)(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move_pruning(state_as_list: list, player: int) -> tuple:\n",
    "    \"\"\" \"\"\"\n",
    "    logging.debug(f\"best_move_pruning, player = {player}\")\n",
    "    if player == 0: # maximizing\n",
    "        return max(\n",
    "            (minimax_pruning(new_state, is_maximizing=False), new_state)\n",
    "            for new_state in all_possible_new_states(state_as_list)\n",
    "        )\n",
    "    else:\n",
    "        return min(\n",
    "            (minimax_pruning(new_state, is_maximizing=True), new_state)\n",
    "            for new_state in all_possible_new_states(state_as_list)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, [1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "s = best_move_pruning([1,2,3], 0)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nimply_move(current_state: Nim, new_state: list) -> Nimply:\n",
    "    \n",
    "    diff = 0\n",
    "    row = len(current_state.rows) #invalid row\n",
    "    \n",
    "    for i in range(len(current_state.rows)):\n",
    "        \n",
    "        if current_state.rows[i] != new_state[i]:\n",
    "            diff = current_state.rows[i] - new_state[i]\n",
    "            row = i\n",
    "            \n",
    "    ply = Nimply(row, diff)\n",
    "\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_agent(state: Nim):\n",
    "\n",
    "    state_as_list = [] # convert the state to list to easier handle the recursion later on\n",
    "\n",
    "    for i in range(len(state.rows)):\n",
    "        state_as_list.append(state.rows[i])\n",
    "\n",
    "    logging.debug(f\"State as a list: {state_as_list}\")\n",
    "\n",
    "    best_move = best_move_pruning(state_as_list, player=0)\n",
    "    \n",
    "\n",
    "    move = best_move[1] # since best_move = (score, [new state])\n",
    "    logging.debug(f\"MOVE: {move}\")\n",
    "    # from best move -> turn it into a nimply\n",
    "    final_move = nimply_move(state, move)\n",
    "\n",
    "    return final_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:State as a list: [1, 3, 5]\n",
      "DEBUG:root:MOVE: [1, 3, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RES: Nimply(row=2, num_objects=3)\n"
     ]
    }
   ],
   "source": [
    "state = [1,1,1,5]\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "player = 1\n",
    "\n",
    "s = Nim(3)\n",
    "res = min_max_agent(s)\n",
    "print(\"RES:\", res)\n",
    "\n",
    "#print(\"state: \", state)\n",
    "\n",
    "#scores = best_move(state, player)\n",
    "#print(scores)\n",
    "\n",
    "#sc = best_move_pruning(state, player)\n",
    "#print(f\"sc {sc}\")\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:status: Initial board  -> <1 3 5 7>\n",
      "DEBUG:root:State as a list: [1, 3, 5, 7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [50], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     winner \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m player\n\u001b[0;32m     14\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstatus: Player \u001b[39m\u001b[39m{\u001b[39;00mwinner\u001b[39m}\u001b[39;00m\u001b[39m won!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m play_nim(min_max_agent, min_max_agent)\n",
      "Cell \u001b[1;32mIn [50], line 9\u001b[0m, in \u001b[0;36mplay_nim\u001b[1;34m(agent1, opponent)\u001b[0m\n\u001b[0;32m      6\u001b[0m player \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m nim:\n\u001b[1;32m----> 9\u001b[0m     ply \u001b[39m=\u001b[39m strategy[player](nim)\n\u001b[0;32m     10\u001b[0m     nim\u001b[39m.\u001b[39mnimming(ply)\n\u001b[0;32m     11\u001b[0m     logging\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstatus: After player \u001b[39m\u001b[39m{\u001b[39;00mplayer\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mnim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [48], line 10\u001b[0m, in \u001b[0;36mmin_max_agent\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      6\u001b[0m     state_as_list\u001b[39m.\u001b[39mappend(state\u001b[39m.\u001b[39mrows[i])\n\u001b[0;32m      8\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mState as a list: \u001b[39m\u001b[39m{\u001b[39;00mstate_as_list\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m best_move \u001b[39m=\u001b[39m best_move_pruning(state_as_list, player\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     13\u001b[0m move \u001b[39m=\u001b[39m best_move[\u001b[39m1\u001b[39m] \u001b[39m# since best_move = (score, [new state])\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMOVE: \u001b[39m\u001b[39m{\u001b[39;00mmove\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [45], line 4\u001b[0m, in \u001b[0;36mbest_move_pruning\u001b[1;34m(state_as_list, player)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m player \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# maximizing\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39;49m(\n\u001b[0;32m      5\u001b[0m         (minimax_pruning(new_state, is_maximizing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), new_state)\n\u001b[0;32m      6\u001b[0m         \u001b[39mfor\u001b[39;49;00m new_state \u001b[39min\u001b[39;49;00m all_possible_new_states(state_as_list)\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(\n\u001b[0;32m     10\u001b[0m         (minimax_pruning(new_state, is_maximizing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), new_state)\n\u001b[0;32m     11\u001b[0m         \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list)\n\u001b[0;32m     12\u001b[0m     )\n",
      "Cell \u001b[1;32mIn [45], line 5\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m player \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# maximizing\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(\n\u001b[1;32m----> 5\u001b[0m         (minimax_pruning(new_state, is_maximizing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), new_state)\n\u001b[0;32m      6\u001b[0m         \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list)\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(\n\u001b[0;32m     10\u001b[0m         (minimax_pruning(new_state, is_maximizing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), new_state)\n\u001b[0;32m     11\u001b[0m         \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list)\n\u001b[0;32m     12\u001b[0m     )\n",
      "Cell \u001b[1;32mIn [44], line 9\u001b[0m, in \u001b[0;36mminimax_pruning\u001b[1;34m(state_as_list, is_maximizing, alpha, beta)\u001b[0m\n\u001b[0;32m      6\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list):\n\u001b[0;32m      8\u001b[0m     scores\u001b[39m.\u001b[39mappend(\n\u001b[1;32m----> 9\u001b[0m         score \u001b[39m:=\u001b[39m minimax_pruning(new_state, \u001b[39mnot\u001b[39;49;00m is_maximizing, alpha, beta)\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m is_maximizing:\n\u001b[0;32m     13\u001b[0m         alpha \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(alpha, score)\n",
      "Cell \u001b[1;32mIn [44], line 9\u001b[0m, in \u001b[0;36mminimax_pruning\u001b[1;34m(state_as_list, is_maximizing, alpha, beta)\u001b[0m\n\u001b[0;32m      6\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list):\n\u001b[0;32m      8\u001b[0m     scores\u001b[39m.\u001b[39mappend(\n\u001b[1;32m----> 9\u001b[0m         score \u001b[39m:=\u001b[39m minimax_pruning(new_state, \u001b[39mnot\u001b[39;49;00m is_maximizing, alpha, beta)\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m is_maximizing:\n\u001b[0;32m     13\u001b[0m         alpha \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(alpha, score)\n",
      "    \u001b[1;31m[... skipping similar frames: minimax_pruning at line 9 (7 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn [44], line 9\u001b[0m, in \u001b[0;36mminimax_pruning\u001b[1;34m(state_as_list, is_maximizing, alpha, beta)\u001b[0m\n\u001b[0;32m      6\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list):\n\u001b[0;32m      8\u001b[0m     scores\u001b[39m.\u001b[39mappend(\n\u001b[1;32m----> 9\u001b[0m         score \u001b[39m:=\u001b[39m minimax_pruning(new_state, \u001b[39mnot\u001b[39;49;00m is_maximizing, alpha, beta)\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m is_maximizing:\n\u001b[0;32m     13\u001b[0m         alpha \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(alpha, score)\n",
      "Cell \u001b[1;32mIn [44], line 7\u001b[0m, in \u001b[0;36mminimax_pruning\u001b[1;34m(state_as_list, is_maximizing, alpha, beta)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m score\n\u001b[0;32m      6\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m new_state \u001b[39min\u001b[39;00m all_possible_new_states(state_as_list):\n\u001b[0;32m      8\u001b[0m     scores\u001b[39m.\u001b[39mappend(\n\u001b[0;32m      9\u001b[0m         score \u001b[39m:=\u001b[39m minimax_pruning(new_state, \u001b[39mnot\u001b[39;00m is_maximizing, alpha, beta)\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m is_maximizing:\n",
      "Cell \u001b[1;32mIn [38], line 7\u001b[0m, in \u001b[0;36mall_possible_new_states\u001b[1;34m(init_state)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(init_state)): \u001b[39m# for every row\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(init_state[row]): \u001b[39m# for the number of elem in row\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m         new_state \u001b[39m=\u001b[39m deepcopy(init_state)\n\u001b[0;32m      9\u001b[0m         new_state[row] \u001b[39m=\u001b[39m new_state[row] \u001b[39m-\u001b[39m i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m#take away i+1 number of elem\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         \u001b[39m#print(\"new state: \", new_state)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\copy.py:202\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deepcopy_list\u001b[39m(x, memo, deepcopy\u001b[39m=\u001b[39mdeepcopy):\n\u001b[0;32m    201\u001b[0m     y \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 202\u001b[0m     memo[\u001b[39mid\u001b[39;49m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    203\u001b[0m     append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[0;32m    204\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def play_nim(agent1: Callable, opponent: Callable):\n",
    "    nim = Nim(4)\n",
    "    logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "    \n",
    "    strategy = (agent1, opponent)\n",
    "    player = 0\n",
    "\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "        player = 1 - player\n",
    "    winner = 1 - player\n",
    "    logging.info(f\"status: Player {winner} won!\")\n",
    "\n",
    "play_nim(min_max_agent, min_max_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f2b8f7d7da3b55c8640ff0ad5b752ba61ffdffe564a4378c820bcd9964834b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
